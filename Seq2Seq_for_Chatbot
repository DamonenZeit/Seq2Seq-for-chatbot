{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["CKgZ1LzT-Hwe","WIutZiZMhuou","1EEaqTNYCvWS"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f6396a6cd8384ad583edaebcfd0599eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e40bbce2baf4e93996363a3335849b2","IPY_MODEL_4f6e0651546740dbac393eb3954a5a2a","IPY_MODEL_1bd6607b9e8146a785dcf1891931c6d3"],"layout":"IPY_MODEL_e8ca1dcfaa414c9c9c4a3230b08b2019"}},"3e40bbce2baf4e93996363a3335849b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b254e5a5f234164afd0b52785fb28e1","placeholder":"​","style":"IPY_MODEL_1e22759a3ec74ea3b898e3fe6e80ff32","value":"Downloading (…)okenizer_config.json: 100%"}},"4f6e0651546740dbac393eb3954a5a2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbc5ffad389941c18cb2e168b70c5613","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_319ab054cd484f01b1b6a02c305cb6f6","value":26}},"1bd6607b9e8146a785dcf1891931c6d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff29482ad5944554ad50bab8f2c73202","placeholder":"​","style":"IPY_MODEL_2140c790e07b41a1a12b830d13955b38","value":" 26.0/26.0 [00:00&lt;00:00, 1.13kB/s]"}},"e8ca1dcfaa414c9c9c4a3230b08b2019":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b254e5a5f234164afd0b52785fb28e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e22759a3ec74ea3b898e3fe6e80ff32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbc5ffad389941c18cb2e168b70c5613":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"319ab054cd484f01b1b6a02c305cb6f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff29482ad5944554ad50bab8f2c73202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2140c790e07b41a1a12b830d13955b38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3049ede88e9141f18d5425b0c7dda648":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e32c9bf98db49ef819b5e03866d303e","IPY_MODEL_d6f1de4dd25b43ed9550331981daff04","IPY_MODEL_2447149942594f2497a41f5c0f3a6dba"],"layout":"IPY_MODEL_acd7c0e3205e47f7baa6691a81e99e50"}},"7e32c9bf98db49ef819b5e03866d303e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a0c237f80ec4aa7bdc2e819a0d38529","placeholder":"​","style":"IPY_MODEL_84d51ca1ae5f499a996cce1ced3e4b77","value":"Downloading (…)lve/main/config.json: 100%"}},"d6f1de4dd25b43ed9550331981daff04":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57a488b310dd412e967b51adbea50ff5","max":642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e4d2369d8b2489e86062a24a26de334","value":642}},"2447149942594f2497a41f5c0f3a6dba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_992e54244dc941ef9f1313dd7278964c","placeholder":"​","style":"IPY_MODEL_598c0c01d771456297aedef26c3d708d","value":" 642/642 [00:00&lt;00:00, 34.4kB/s]"}},"acd7c0e3205e47f7baa6691a81e99e50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0c237f80ec4aa7bdc2e819a0d38529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d51ca1ae5f499a996cce1ced3e4b77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57a488b310dd412e967b51adbea50ff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4d2369d8b2489e86062a24a26de334":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"992e54244dc941ef9f1313dd7278964c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"598c0c01d771456297aedef26c3d708d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"288d49ad3ef94e618688fa3a7bcfaed5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_027d6a7ed0904226b7e9483cbfce9036","IPY_MODEL_8a9bb976fa054663a98ee69c09e4b0a9","IPY_MODEL_8fb887bf100d4d5ab1f80e366dfefadf"],"layout":"IPY_MODEL_934f61cf542e469496d051bd553e0b0b"}},"027d6a7ed0904226b7e9483cbfce9036":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96185011ce5c4bafb9b3d7cb687b1608","placeholder":"​","style":"IPY_MODEL_17345716f0b2452897030e9fea608697","value":"Downloading (…)olve/main/vocab.json: 100%"}},"8a9bb976fa054663a98ee69c09e4b0a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_245a7df607f24800abcf10dd4871a92e","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e80ce5d53f574a19bb2a90c612996908","value":1042301}},"8fb887bf100d4d5ab1f80e366dfefadf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_862350e1e6514ec99b74339956b03729","placeholder":"​","style":"IPY_MODEL_6a3ef68f822247eea162c47b3f74ffa7","value":" 1.04M/1.04M [00:00&lt;00:00, 20.9MB/s]"}},"934f61cf542e469496d051bd553e0b0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96185011ce5c4bafb9b3d7cb687b1608":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17345716f0b2452897030e9fea608697":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"245a7df607f24800abcf10dd4871a92e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e80ce5d53f574a19bb2a90c612996908":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"862350e1e6514ec99b74339956b03729":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a3ef68f822247eea162c47b3f74ffa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eca2b5cd54c4b66b626a63aa0bf78d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9aa066c2a0e443d9a79226466d20cefd","IPY_MODEL_d42e4ded7a014e00be7c684fd69e5173","IPY_MODEL_0322e7dcba4a4b0098e4ae07fba870cf"],"layout":"IPY_MODEL_89d368a9bbfe45929eb177b3b04ccb06"}},"9aa066c2a0e443d9a79226466d20cefd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdc41ffd82646b9858d4b41e9baeff5","placeholder":"​","style":"IPY_MODEL_744d49a1a0c0499fbfd397d3e59b3888","value":"Downloading (…)olve/main/merges.txt: 100%"}},"d42e4ded7a014e00be7c684fd69e5173":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_326c400f3563432d89fee56a9658c546","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58f5c26f53a24872b313daf314bfef68","value":456318}},"0322e7dcba4a4b0098e4ae07fba870cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf80b3ba0ced4ff5831f126eed589d63","placeholder":"​","style":"IPY_MODEL_a8428f8c08134f8fb2c0f7a727b5a502","value":" 456k/456k [00:00&lt;00:00, 9.39MB/s]"}},"89d368a9bbfe45929eb177b3b04ccb06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcdc41ffd82646b9858d4b41e9baeff5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744d49a1a0c0499fbfd397d3e59b3888":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"326c400f3563432d89fee56a9658c546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58f5c26f53a24872b313daf314bfef68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf80b3ba0ced4ff5831f126eed589d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8428f8c08134f8fb2c0f7a727b5a502":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a1347bee95f413e8b9a071df3467a3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfba9fee791748c7b78ce8d462104bd9","IPY_MODEL_d27282dbc3a14657b6c2db8dae9f9786","IPY_MODEL_f0f85be01a7c42dfb931f8741e5c920f"],"layout":"IPY_MODEL_cc6017b1ed004f50bd5e19a0f8d19796"}},"cfba9fee791748c7b78ce8d462104bd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e74bfff0710431e82729261f73faa22","placeholder":"​","style":"IPY_MODEL_cf2e24b2996a4828a5c79061d7847a79","value":"Downloading pytorch_model.bin: 100%"}},"d27282dbc3a14657b6c2db8dae9f9786":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7bf66b3d3d54786aae080351ff648c7","max":862955157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a15eaf8238d48649af154fe0e645b1b","value":862955157}},"f0f85be01a7c42dfb931f8741e5c920f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1a85e8306284091ab6db6ab76c97aa0","placeholder":"​","style":"IPY_MODEL_9001ecdafad54c1d858c23bfb174f4f4","value":" 863M/863M [00:03&lt;00:00, 166MB/s]"}},"cc6017b1ed004f50bd5e19a0f8d19796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e74bfff0710431e82729261f73faa22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf2e24b2996a4828a5c79061d7847a79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7bf66b3d3d54786aae080351ff648c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a15eaf8238d48649af154fe0e645b1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1a85e8306284091ab6db6ab76c97aa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9001ecdafad54c1d858c23bfb174f4f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d30100e9bc6d4c688b5a7358aad67b62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48f40c1b1edf488395423745f3e420b2","IPY_MODEL_ee57b97684e04abb9b23d1fff131977d","IPY_MODEL_79146bcdaac54ecc88d384250a05073c"],"layout":"IPY_MODEL_b46fd2cc3b9140f7a3cd2c59fcfccdcb"}},"48f40c1b1edf488395423745f3e420b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc5f55080e064b98af786403543178fc","placeholder":"​","style":"IPY_MODEL_6df9a0a938cc4f8f853257548d97ddb1","value":"Downloading (…)neration_config.json: 100%"}},"ee57b97684e04abb9b23d1fff131977d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_832179e4b8864a7790873dbd6fd03eaf","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34e62f90f4c0459f8827b8cb7ad3921c","value":124}},"79146bcdaac54ecc88d384250a05073c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34f06ffceebd458a80d151634b0352b4","placeholder":"​","style":"IPY_MODEL_745951c13c414415b3b4325320642d1c","value":" 124/124 [00:00&lt;00:00, 5.58kB/s]"}},"b46fd2cc3b9140f7a3cd2c59fcfccdcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5f55080e064b98af786403543178fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df9a0a938cc4f8f853257548d97ddb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"832179e4b8864a7790873dbd6fd03eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34e62f90f4c0459f8827b8cb7ad3921c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34f06ffceebd458a80d151634b0352b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"745951c13c414415b3b4325320642d1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#Transformer Model"],"metadata":{"id":"CKgZ1LzT-Hwe"}},{"cell_type":"markdown","source":["##Transformer Model cho chatbot"],"metadata":{"id":"WIutZiZMhuou"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwLzX1dCebXy","executionInfo":{"status":"ok","timestamp":1682024617155,"user_tz":-420,"elapsed":19303,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"fed9281f-5ec7-416f-d788-d92f967881c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["#Bước 1: Cài đặt và import thư viện Transformers của Hugging Face.\n","\n","\n","!pip install transformers\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","source":["#Bước 2: Tải mô hình và tokenizer của Transformer Model. Mô hình được sử dụng trong ví dụ này là `microsoft/DialoGPT-medium`.\n","model_name = \"microsoft/DialoGPT-medium\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["f6396a6cd8384ad583edaebcfd0599eb","3e40bbce2baf4e93996363a3335849b2","4f6e0651546740dbac393eb3954a5a2a","1bd6607b9e8146a785dcf1891931c6d3","e8ca1dcfaa414c9c9c4a3230b08b2019","1b254e5a5f234164afd0b52785fb28e1","1e22759a3ec74ea3b898e3fe6e80ff32","dbc5ffad389941c18cb2e168b70c5613","319ab054cd484f01b1b6a02c305cb6f6","ff29482ad5944554ad50bab8f2c73202","2140c790e07b41a1a12b830d13955b38","3049ede88e9141f18d5425b0c7dda648","7e32c9bf98db49ef819b5e03866d303e","d6f1de4dd25b43ed9550331981daff04","2447149942594f2497a41f5c0f3a6dba","acd7c0e3205e47f7baa6691a81e99e50","7a0c237f80ec4aa7bdc2e819a0d38529","84d51ca1ae5f499a996cce1ced3e4b77","57a488b310dd412e967b51adbea50ff5","3e4d2369d8b2489e86062a24a26de334","992e54244dc941ef9f1313dd7278964c","598c0c01d771456297aedef26c3d708d","288d49ad3ef94e618688fa3a7bcfaed5","027d6a7ed0904226b7e9483cbfce9036","8a9bb976fa054663a98ee69c09e4b0a9","8fb887bf100d4d5ab1f80e366dfefadf","934f61cf542e469496d051bd553e0b0b","96185011ce5c4bafb9b3d7cb687b1608","17345716f0b2452897030e9fea608697","245a7df607f24800abcf10dd4871a92e","e80ce5d53f574a19bb2a90c612996908","862350e1e6514ec99b74339956b03729","6a3ef68f822247eea162c47b3f74ffa7","1eca2b5cd54c4b66b626a63aa0bf78d4","9aa066c2a0e443d9a79226466d20cefd","d42e4ded7a014e00be7c684fd69e5173","0322e7dcba4a4b0098e4ae07fba870cf","89d368a9bbfe45929eb177b3b04ccb06","bcdc41ffd82646b9858d4b41e9baeff5","744d49a1a0c0499fbfd397d3e59b3888","326c400f3563432d89fee56a9658c546","58f5c26f53a24872b313daf314bfef68","bf80b3ba0ced4ff5831f126eed589d63","a8428f8c08134f8fb2c0f7a727b5a502","9a1347bee95f413e8b9a071df3467a3f","cfba9fee791748c7b78ce8d462104bd9","d27282dbc3a14657b6c2db8dae9f9786","f0f85be01a7c42dfb931f8741e5c920f","cc6017b1ed004f50bd5e19a0f8d19796","5e74bfff0710431e82729261f73faa22","cf2e24b2996a4828a5c79061d7847a79","a7bf66b3d3d54786aae080351ff648c7","9a15eaf8238d48649af154fe0e645b1b","d1a85e8306284091ab6db6ab76c97aa0","9001ecdafad54c1d858c23bfb174f4f4","d30100e9bc6d4c688b5a7358aad67b62","48f40c1b1edf488395423745f3e420b2","ee57b97684e04abb9b23d1fff131977d","79146bcdaac54ecc88d384250a05073c","b46fd2cc3b9140f7a3cd2c59fcfccdcb","bc5f55080e064b98af786403543178fc","6df9a0a938cc4f8f853257548d97ddb1","832179e4b8864a7790873dbd6fd03eaf","34e62f90f4c0459f8827b8cb7ad3921c","34f06ffceebd458a80d151634b0352b4","745951c13c414415b3b4325320642d1c"]},"id":"fRIFvH1hnnyX","executionInfo":{"status":"ok","timestamp":1682024666618,"user_tz":-420,"elapsed":14890,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"a9ace96e-3c6d-404b-ddd3-75a4014320c6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6396a6cd8384ad583edaebcfd0599eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3049ede88e9141f18d5425b0c7dda648"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"288d49ad3ef94e618688fa3a7bcfaed5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eca2b5cd54c4b66b626a63aa0bf78d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/863M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1347bee95f413e8b9a071df3467a3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d30100e9bc6d4c688b5a7358aad67b62"}},"metadata":{}}]},{"cell_type":"code","source":["#Bước 3: Tạo hàm chatbot để tương tác với mô hình.\n","\n","def chatbot(user_input):\n","    # Chuyển đổi câu nhận dạng được từ người dùng thành mã token\n","    input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors=\"pt\")\n","    # Tạo câu trả lời của chatbot từ câu hỏi của người dùng\n","    bot_output = model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n","    # Giải mã mã token để lấy được câu trả lời của chatbot\n","    bot_response = tokenizer.decode(bot_output[0], skip_special_tokens=True)\n","    return bot_response"],"metadata":{"id":"rXCHhMHinzfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","        \n","if len(test_data) == 0:\n","    print(\"File 'test.txt' mới không có dữ liệu\")\n","elif len(test_data[0]) != 2:\n","    print(\"File 'test.txt' mới không phải là định dạng cặp câu hỏi - câu trả lời\")\n","else:\n","    test_questions, test_answers = zip(*test_data)\n","    print(f\"{len(test_data)} cặp câu hỏi - câu trả lời đã được tải lên.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmAKEayXw0Gn","executionInfo":{"status":"ok","timestamp":1682012591594,"user_tz":-420,"elapsed":317,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"8ece081a-e08c-48bd-899c-d696299fafd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5 cặp câu hỏi - câu trả lời đã được tải lên.\n"]}]},{"cell_type":"code","source":["#Bước 4: Tải bộ dữ liệu Test và chạy hàm chatbot để tương tác với chatbot. Kết quả có thể được đánh giá bằng các độ đo như BLEU hoặc ROUGE.\n","\n","test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","        \n","test_questions, test_answers = zip(*test_data)\n","\n","# Đánh giá chatbot bằng BLEU score\n","from nltk.translate.bleu_score import sentence_bleu\n","bleu_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    bleu_score = sentence_bleu([reference], answer)\n","    bleu_scores.append(bleu_score)\n","    \n","print(\"Mean BLEU score:\", sum(bleu_scores) / len(bleu_scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hjxk9uXn37k","executionInfo":{"status":"ok","timestamp":1682010708042,"user_tz":-420,"elapsed":22482,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"f6e58a9a-f03a-488e-e28b-9338b0a5fff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Mean BLEU score: 0.03616060908157706\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","\n","test_questions, test_answers = zip(*test_data)\n","\n","# Đánh giá chatbot bằng BLEU score\n","bleu_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    bleu_score = sentence_bleu([reference], answer)\n","    bleu_scores.append(bleu_score)\n","    print(f\"Question: {question}\")\n","    print(f\"Bot Answer: {answer}\")\n","    print(f\"Reference Answer: {reference}\")\n","    print(f\"BLEU score: {bleu_score}\\n\")\n","\n","mean_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(f\"\\nMean BLEU score: {mean_bleu_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aIvkAGcPrw8K","executionInfo":{"status":"ok","timestamp":1682011305800,"user_tz":-420,"elapsed":17086,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"fb425f7f-0b59-45c7-a4b8-34d0ff83b10a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Xin chào!\n","Bot Answer: Xin chào!I'm not sure if you're serious, but that's a Chinese name.\n","Reference Answer: Bạn có khỏe không?\n","BLEU score: 1.2023863163879976e-78\n","\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Bạn là ai?\n","Bot Answer: Bạn là ai?I'm not sure what you're asking.\n","Reference Answer: Mình là một chatbot.\n","BLEU score: 0.10040404863260693\n","\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Bạn ở đâu?\n","Bot Answer: Bạn ở đâu?I'm not sure what you're trying to say.\n","Reference Answer: Tôi ở Sài Gòn.\n","BLEU score: 1.2956399269599786e-78\n","\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Bạn khỏe không\n","Bot Answer: Bạn khỏe khôngI'm not sure if you're being serious or not, but I'm going to go with the latter.\n","Reference Answer: Tôi khỏe.\n","BLEU score: 0.039814819250720467\n","\n","Question: Nghề nghiệp của bạn là gì?\n","Bot Answer: Nghề nghiệp của bạn là gì?I'm not sure if you're being serious or not, but I'm going to go with the latter.\n","Reference Answer: Tôi là một sinh viên.\n","BLEU score: 0.040584177524557896\n","\n","\n","Mean BLEU score: 0.03616060908157706\n"]}]},{"cell_type":"code","source":["#test2_txt"],"metadata":{"id":"7VOz_ddJfKnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test2.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","        \n","if len(test_data) == 0:\n","    print(\"File 'test.txt' mới không có dữ liệu\")\n","elif len(test_data[0]) != 2:\n","    print(\"File 'test.txt' mới không phải là định dạng cặp câu hỏi - câu trả lời\")\n","else:\n","    test_questions, test_answers = zip(*test_data)\n","    print(f\"{len(test_data)} cặp câu hỏi - câu trả lời đã được tải lên.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p42ZClM1wmis","executionInfo":{"status":"ok","timestamp":1682012550423,"user_tz":-420,"elapsed":312,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"c4bebaed-8654-4ce3-c6d4-8f844ead6f65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4 cặp câu hỏi - câu trả lời đã được tải lên.\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","\n","test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test2.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","\n","test_questions, test_answers = zip(*test_data)\n","\n","# Đánh giá chatbot bằng BLEU score\n","bleu_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    bleu_score = sentence_bleu([reference], answer)\n","    bleu_scores.append(bleu_score)\n","    print(f\"Question: {question}\")\n","    print(f\"Bot Answer: {answer}\")\n","    print(f\"Reference Answer: {reference}\")\n","    print(f\"BLEU score: {bleu_score}\\n\")\n","\n","mean_bleu_score = sum(bleu_scores) / len(bleu_scores)\n","print(f\"\\nMean BLEU score: {mean_bleu_score}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682012518382,"user_tz":-420,"elapsed":6781,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"95772a14-25aa-4424-ba81-749019a0c8a5","id":"Bcx5-cfStBAi"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Who are you?\n","Bot Answer: Who are you?I am the one who knocks.\n","Reference Answer: I'm Jhon\n","BLEU score: 5.157006819435075e-155\n","\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: Where do you come from?\n","Bot Answer: Where do you come from?I'm from the UK, but I'm from the US.\n","Reference Answer: I come from Vietnam\n","BLEU score: 0.1742927856295149\n","\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Question: How old are you?\n","Bot Answer: How old are you?I'm 21\n","Reference Answer: I'm 20\n","BLEU score: 0.161692143534558\n","\n","Question: What is your job now?\n","Bot Answer: What is your job now?I'm a software engineer.\n","Reference Answer: I'm a student\n","BLEU score: 0.14722500792577722\n","\n","\n","Mean BLEU score: 0.12080248427246251\n"]}]},{"cell_type":"markdown","source":["##Cải thiện độ chính xác"],"metadata":{"id":"tPkRFS0b1MZm"}},{"cell_type":"markdown","source":["###*Sử dụng kỹ thuật ensemble: Việc sử dụng nhiều mô hình để tạo ra các câu trả lời và sau đó kết hợp chúng có thể giúp cải thiện độ chính xác của chatbot.*\n"],"metadata":{"id":"rrhsXcf8jucS"}},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import pandas as pd\n","from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer"],"metadata":{"id":"rjpJW0j81Po6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('test.txt', 'r', encoding='utf8') as f:\n","    data = f.readlines()\n","\n","questions = []\n","answers = []\n","\n","for i in range(0, len(data), 2):\n","    if i+1 < len(data):\n","        questions.append(data[i].strip())\n","        answers.append(data[i+1].strip())\n","\n","df = pd.DataFrame({'input': questions, 'output': answers})\n","\n","df.to_csv('data.csv', index=None)\n"],"metadata":{"id":"R20LRJbm5iCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_names = [\"microsoft/DialoGPT-medium\", \"microsoft/DialoGPT-small\"]\n","models = []\n","tokenizers = []\n","\n","for name in model_names:\n","    tokenizer = AutoTokenizer.from_pretrained(name)\n","    tokenizers.append(tokenizer)\n","    model = AutoModelForCausalLM.from_pretrained(name)\n","    models.append(model)\n","\n","def chatbot(user_input):\n","    inputs = [tokenizer.encode(user_input + tokenizer.eos_token, return_tensors=\"pt\") for tokenizer in tokenizers]\n","    bot_outputs = [model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id) for model, input_ids, tokenizer in zip(models, inputs, tokenizers)]\n","    bot_responses = [tokenizer.decode(bot_output[0], skip_special_tokens=True) for bot_output, tokenizer in zip(bot_outputs, tokenizers)]\n","    return max(bot_responses, key=len)\n","\n","test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        test_data.append(line.strip().split(\"\\t\"))\n","        \n","test_questions, test_answers = zip(*test_data)\n","\n","# Đánh giá chatbot bằng BLEU score\n","from nltk.translate.bleu_score import sentence_bleu\n","bleu_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    bleu_score = sentence_bleu([reference], answer)\n","    bleu_scores.append(bleu_score)\n","    \n","print(\"Mean BLEU score:\", sum(bleu_scores) / len(bleu_scores))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HyGoRiplOLUq","executionInfo":{"status":"ok","timestamp":1682020916408,"user_tz":-420,"elapsed":32320,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"cd40d606-357e-477d-f2d6-fc71281571b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Mean BLEU score: 0.03546133480290407\n"]}]},{"cell_type":"markdown","source":["###*Tiền xử lý đơn giản bao gồm chuyển đổi thành chữ thường, loại bỏ các stop word và chỉ giữ lại các từ chữ cái.*"],"metadata":{"id":"xoAPrBfxmO2g"}},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    tokens = text.lower().split()\n","    tokens = [tok for tok in tokens if tok.isalpha()]\n","    tokens = [tok for tok in tokens if tok not in stop_words]\n","    return ' '.join(tokens)\n","\n","test_data = [] #Các cặp câu hỏi và câu trả lời trong bộ Test\n","with open(\"test.txt\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        q, a = line.strip().split(\"\\t\")\n","        q = preprocess(q)\n","        test_data.append((q, a))\n","        \n","test_questions, test_answers = zip(*test_data)\n","\n","# Đánh giá chatbot bằng BLEU score\n","from nltk.translate.bleu_score import sentence_bleu\n","bleu_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    bleu_score = sentence_bleu([reference], answer)\n","    bleu_scores.append(bleu_score)\n","    \n","print(\"Mean BLEU score:\", sum(bleu_scores) / len(bleu_scores))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ff4ltpJlgf_","executionInfo":{"status":"ok","timestamp":1682026546833,"user_tz":-420,"elapsed":1502,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"988ef6ae-d815-4b24-d4eb-ec78d51fe6d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Mean BLEU score: 0.05804072589725651\n"]}]},{"cell_type":"markdown","source":["###*sử dụng thư viện ROUGE để đánh giá chatbot bằng ROUGE score*"],"metadata":{"id":"CAi2qk_2pmI8"}},{"cell_type":"code","source":["!pip install rouge\n","from rouge import Rouge\n","\n","# Tạo đối tượng Rouge\n","rouge = Rouge()\n","\n","# Đánh giá chatbot bằng ROUGE score\n","from nltk.translate.bleu_score import sentence_bleu\n","rouge_scores = []\n","for i, question in enumerate(test_questions):\n","    answer = chatbot(question)\n","    reference = test_answers[i]\n","    rouge_score = rouge.get_scores(answer, reference)[0]['rouge-l']['f']\n","    rouge_scores.append(rouge_score)\n","    \n","print(\"Mean ROUGE score:\", sum(rouge_scores) / len(rouge_scores))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIdazqzbo2g9","executionInfo":{"status":"ok","timestamp":1682027437184,"user_tz":-420,"elapsed":21250,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"6cd3f5d2-a3b7-498c-c067-2953b9777c39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: rouge in /usr/local/lib/python3.9/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from rouge) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Mean ROUGE score: 0.09576719311374271\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"tZJ9VG7Rcvk8"}},{"cell_type":"markdown","source":["#Seq2Seq (Sequence-to-Sequence)"],"metadata":{"id":"tmKxAzr6c-T7"}},{"cell_type":"markdown","source":["##*Seq2Seq*"],"metadata":{"id":"m3a_nCgcdH6y"}},{"cell_type":"code","source":["import csv\n","import numpy as np\n","data = [\n","    [\"Hi, what's your name?\", \"My name is VoiceGPT.\"],\n","    [\"How are you?\", \"I'm doing well, thank you for asking.\"],\n","    [\"What can you do?\", \"I can help answer questions or have casual conversations with you.\"],\n","    [\"How old are you?\", \"I'm 20 years old.\"],\n","    [\"Where do you come from?\", \"I'm from Vietnam.\"],\n","    [\"What is your job now?\", \"I'm a student.\"],\n","    [\"Do you know me?\", \"No, I don't.\"]\n","    #[\"Are you free now?\", \"No, I'm busy.\"],\n","    #[\"Do you speak English?\", \"A little, but not very well.\"],\n","    #[\"What time it is?\", \"It’s 5:10PM.\"],\n","]\n","\n","# Lưu vào file csv\n","with open('data.csv', mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(data)\n"],"metadata":{"id":"pQ066qvbjNvo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = [\n","    [\"What are you free now?\", \"No, I'm busy.\"],\n","    [\"Do you do with me?\", \"No, I refuse.\"],\n","    [\"What time it is?\", \"It is 5 o'clock.\"]\n","]\n","\n","# Lưu vào file csv\n","with open('test.csv', mode='w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerows(test_data)"],"metadata":{"id":"dHmROvRTNY9T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","!pip install nltk"],"metadata":{"id":"6l3HLzJnbiiZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683704794976,"user_tz":-420,"elapsed":6781,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"f33c56a1-7da7-4f79-de11-b98b9eb63633"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]}]},{"cell_type":"code","source":["# Import thư viện Keras\n","\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","# Định nghĩa các tham số cho mô hình\n","batch_size = 32  # Số lượng câu hỏi - trả lời sẽ được sử dụng trong mỗi bước cập nhật\n","epochs = 5  # Số lượng vòng lặp để huấn luyện mô hình\n","latent_dim = 256  # Kích thước của hidden state và cell state trong LSTM layer\n","num_samples = 10000  # Số lượng câu hỏi - trả lời sẽ được sử dụng để huấn luyện mô hình (từ file csv)\n","\n","data_path = 'data.csv'\n","\n","# Đọc dữ liệu từ file csv\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    reader = csv.reader(f, delimiter=',')\n","    for row in reader:\n","        input_text, target_text = row\n","        # Sử dụng tab để làm ký tự bắt đầu và kết thúc cho câu trả lời\n","        target_text = '\\t' + target_text + '\\n'\n","\n","        input_texts.append(input_text)\n","        target_texts.append(target_text)\n","\n","        for char in input_text:\n","            if char not in input_characters:\n","                input_characters.add(char)\n","\n","        for char in target_text:\n","            if char not in target_characters:\n","                target_characters.add(char)\n","\n","# Sắp xếp các ký tự theo thứ tự bảng chữ cái\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","\n","# Tính toán độ dài tối đa của câu hỏi và câu trả lời\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","# Tạo bộ từ điển để mã hóa các ký tự thành số nguyên\n","input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n","\n","# Khởi tạo các ma trận đầu vào và đầu ra\n","encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","decoder_input_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","\n","# Điền các giá trị cho encoder_input_data và decoder_input_data\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.0\n","\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, target_token_index[char]] = 1.0\n","\n","        if t > 0:\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n","\n","# Định nghĩa encoder\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","# Định nghĩa decoder\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Xây dựng mô hình toàn cục\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Tiến hành huấn luyện mô hình\n","#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","#model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","model.fit([encoder_input_data[:5000], decoder_input_data[:5000]], decoder_target_data[:5000], batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","# Lưu trọng số mô hình\n","model.save_weights('chatbot_model.h5')\n","\n","# Tính perplexity trên tập test\n","test_loss = model.evaluate([encoder_input_data[5000:], decoder_input_data[5000:]], decoder_target_data[5000:], batch_size=batch_size)\n","perplexity = pow(2, test_loss)\n","print('Perplexity: {}'.format(perplexity))\n","\n"],"metadata":{"id":"Amepc4yukEEw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683705070293,"user_tz":-420,"elapsed":266413,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"995ae206-5de1-4204-a694-c30187552f65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","125/125 [==============================] - 66s 439ms/step - loss: 0.0028 - val_loss: 0.0000e+00\n","Epoch 2/5\n","125/125 [==============================] - 46s 364ms/step - loss: 0.0029 - val_loss: 0.0000e+00\n","Epoch 3/5\n","125/125 [==============================] - 41s 328ms/step - loss: 0.0029 - val_loss: 0.0000e+00\n","Epoch 4/5\n","125/125 [==============================] - 42s 340ms/step - loss: 0.0029 - val_loss: 0.0000e+00\n","Epoch 5/5\n","125/125 [==============================] - 42s 338ms/step - loss: 0.0029 - val_loss: 0.0000e+00\n","157/157 [==============================] - 16s 103ms/step - loss: 0.0000e+00\n","Perplexity: 1.0\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"D4xuOiyXdkbK"}},{"cell_type":"code","source":["# Đánh giá mô hình bằng perplexity trên tập test\n","test_loss = model.evaluate([encoder_input_data[5000:], decoder_input_data[5000:]], decoder_target_data[5000:], verbose=0)\n","test_perplexity = np.exp(test_loss)\n","print('Perplexity trên tập test: {:.2f}'.format(test_perplexity))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NxC_qkTQyfka","executionInfo":{"status":"ok","timestamp":1683705098997,"user_tz":-420,"elapsed":21060,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"e4febece-e900-4863-b336-d9a3abcce8f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity trên tập test: 1.00\n"]}]},{"cell_type":"code","source":["# Tính BLEU score trên tập test\n","target_token_index_inv = dict((i, char) for char, i in target_token_index.items())\n","\n","test_samples = 10\n","total_score = 0\n","for i in range(test_samples):\n","    # Chọn ngẫu nhiên một câu hỏi trong tập test\n","    input_seq = encoder_input_data[5000 + i : 5000 + i + 1]\n","\n","    # Dự đoán câu trả lời cho câu hỏi đó\n","    predicted_seq = model.predict([input_seq, np.zeros((1, max_decoder_seq_length, num_decoder_tokens))])[0]\n","\n","    # Chuyển đổi predicted_seq và target_seq sang dạng chuỗi ký tự\n","    predicted_seq = [np.argmax(token) for token in predicted_seq]\n","    target_seq = decoder_target_data[5000 + i]\n","    target_seq = [np.argmax(token) for token in target_seq]\n","\n","    predicted_text = ''.join([target_token_index_inv[token] for token in predicted_seq])\n","    target_text = ''.join([target_token_index_inv[token] for token in target_seq])\n","\n","    # Tính BLEU score cho đối chiếu giữa predicted_text và target_text\n","    score = sentence_bleu([target_text], predicted_text)\n","    total_score += score\n","\n","average_score = total_score / test_samples\n","print('Average BLEU Score: {}'.format(average_score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2d4DSJLcPxD","executionInfo":{"status":"ok","timestamp":1683705111224,"user_tz":-420,"elapsed":2134,"user":{"displayName":"Phan Nhật Hoàng Anh","userId":"12247794173890880663"}},"outputId":"ebab2211-183b-4439-a7a7-ac51e1ee2a98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 987ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 44ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Average BLEU Score: 0.0\n"]}]},{"cell_type":"markdown","source":["## *Seq2Seq with chatbot_data*"],"metadata":{"id":"JJeY7A75iYel"}},{"cell_type":"code","source":["import csv\n","import numpy as np"],"metadata":{"id":"eeOdgqHiitTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sử dụng pandas để đọc file dữ liệu .txt và chuyển nó thành dataframe.\n","# Phương pháp này được sử dụng để đọc dữ liệu từ file .txt của bộ dữ liệu và chuyển nó thành dataframe để thuận tiện trong việc xử lý và lưu trữ.\n","\n","import pandas as pd\n","# Đường dẫn file .txt\n","file_path = \"data1.txt\"\n","\n","# Đọc file .txt bằng pandas và lưu vào dataframe\n","df = pd.read_csv(file_path, delimiter='\\t', header=None)\n"],"metadata":{"id":"6OL96aTDi1jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lưu dataframe vào file .csv sử dụng `pd.to_csv()`\n","# Phương pháp này được sử dụng để lưu dữ liệu từ dataframe vào file .csv để thuận tiện cho việc đọc và sử dụng lại bộ dữ liệu.\n","\n","csv_file_path = \"data1.csv\"\n","\n","# Lưu dataframe thành file .csv\n","df.to_csv(csv_file_path, index=False)"],"metadata":{"id":"p-_7l6pZNbSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.translate.bleu_score import sentence_bleu\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684239938567,"user_tz":-420,"elapsed":6278,"user":{"displayName":"Tengi “10G.SZ” Seizo","userId":"17698370472858551934"}},"outputId":"3e6df109-c5cd-4d83-d809-3897d82d3232","id":"I2T6eRX7i5-1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]}]},{"cell_type":"code","source":["# Import thư viện Keras\n","\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense\n","\n","# Định nghĩa các tham số cho mô hình\n","batch_size = 32  # Số lượng câu hỏi - trả lời sẽ được sử dụng trong mỗi bước cập nhật\n","epochs = 5  # Số lượng vòng lặp để huấn luyện mô hình\n","latent_dim = 256  # Kích thước của hidden state và cell state trong LSTM layer\n","num_samples = 10000  # Số lượng câu hỏi - trả lời sẽ được sử dụng để huấn luyện mô hình (từ file csv)\n","\n","data_path = 'data1.csv'\n","\n","# Đọc dữ liệu từ file data1.csv và lưu vào các biến input_texts, target_texts, input_characters và target_characters.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    reader = csv.reader(f, delimiter=',')\n","    for row in reader:\n","        input_text, target_text = row\n","        # Sử dụng tab để làm ký tự bắt đầu và kết thúc cho câu trả lời\n","        target_text = '\\t' + target_text + '\\n'\n","\n","        input_texts.append(input_text)\n","        target_texts.append(target_text)\n","\n","        for char in input_text:\n","            if char not in input_characters:\n","                input_characters.add(char)\n","\n","        for char in target_text:\n","            if char not in target_characters:\n","                target_characters.add(char)\n","\n","# Sắp xếp các ký tự theo thứ tự bảng chữ cái\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","\n","# Tính toán độ dài tối đa của câu hỏi và câu trả lời\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","# Tạo bộ từ điển để mã hóa các ký tự thành số nguyên\n","input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n","\n","\n","\n","#  Sử dụng `np.zeros()` để khởi tạo ma trận đầu vào và đầu ra cho encoder và decoder.\n","# Ma trận được tạo ra để lưu trữ các câu hỏi và câu trả lời, và điền vào các giá trị cho các ma trận này dựa trên bộ dữ liệu huấn luyện, từ đó tạo ra các bộ dữ liệu đầu vào và đầu ra cho mô hình.\n","encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n","decoder_input_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n","\n","\n","\n","# Điền các giá trị cho encoder_input_data và decoder_input_data\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.0\n","\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, target_token_index[char]] = 1.0\n","\n","        if t > 0:\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n","\n","\n","# Định nghĩa encoder:  Sử dụng `Input()` và `LSTM` layer trong Keras để xây dựng các phần encoder và decoder của mô hình\n","# Phương pháp này được sử dụng để xây dựng mô hình seq2seq, bao gồm phần encoder và decoder. \n","# Các thành phần của encoder bao gồm một lớp đầu vào và một lớp LSTM. Decoder cũng có các thành phần tương tự với phần decoder của mô hình được định nghĩa bằng một lớp đầu vào và một lớp LSTM.\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","# Định nghĩa decoder\n","decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Xây dựng mô hình toàn cục\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# Tiến hành huấn luyện mô hình\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","model.fit([encoder_input_data[:5000], decoder_input_data[:5000]], decoder_target_data[:5000], batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","# Phương pháp này được sử dụng để huấn luyện mô hình, bao gồm compile và fit mô hình với các tham số tùy chọn như \n","# tốc độ học (optimizer), hàm mất mát (loss), số lượng lô (batch size), vòng lặp (epochs), và tỉ lệ phân chia dữ liệu huấn luyện / kiểm tra tại mỗi vòng lặp.\n","\n","# Lưu trọng số mô hình\n","model.save_weights('chatbot_model.h5')\n","\n","# Tính perplexity trên tập test bằng cách sử dụng `model.evaluate()` để đánh giá mô hình, tính perplexity và BLEU score:\n","test_loss = model.evaluate([encoder_input_data[5000:], decoder_input_data[5000:]], decoder_target_data[5000:], batch_size=batch_size)\n","perplexity = pow(2, test_loss)\n","print('Perplexity: {}'.format(perplexity))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684240043757,"user_tz":-420,"elapsed":79251,"user":{"displayName":"Tengi “10G.SZ” Seizo","userId":"17698370472858551934"}},"outputId":"cab3f9f0-1286-4e9e-ed1c-f3c5fdaf1dba","id":"MIhwCadwi8JB"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","125/125 [==============================] - 19s 77ms/step - loss: 0.2079 - val_loss: 0.2082\n","Epoch 2/5\n","125/125 [==============================] - 7s 58ms/step - loss: 0.2055 - val_loss: 0.2065\n","Epoch 3/5\n","125/125 [==============================] - 7s 56ms/step - loss: 0.2052 - val_loss: 0.2062\n","Epoch 4/5\n","125/125 [==============================] - 7s 58ms/step - loss: 0.2046 - val_loss: 0.2056\n","Epoch 5/5\n","125/125 [==============================] - 7s 57ms/step - loss: 0.2036 - val_loss: 0.2056\n","157/157 [==============================] - 5s 30ms/step - loss: 0.1930\n","Perplexity: 1.1431511137288122\n"]}]},{"cell_type":"code","source":["# Đánh giá mô hình bằng perplexity trên tập test\n","test_loss = model.evaluate([encoder_input_data[5000:], decoder_input_data[5000:]], decoder_target_data[5000:], verbose=0)\n","test_perplexity = np.exp(test_loss)\n","print('Perplexity trên tập test: {:.2f}'.format(test_perplexity))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684240414921,"user_tz":-420,"elapsed":9732,"user":{"displayName":"Tengi “10G.SZ” Seizo","userId":"17698370472858551934"}},"outputId":"9b3e2479-1912-4722-a15e-88bf9b5694bb","id":"pxmsSXjajYFG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity trên tập test: 1.21\n"]}]},{"cell_type":"code","source":["# Tính BLEU score trên tập test\n","target_token_index_inv = dict((i, char) for char, i in target_token_index.items())\n","\n","test_samples = 10\n","total_score = 0\n","for i in range(test_samples):\n","    # Chọn ngẫu nhiên một câu hỏi trong tập test\n","    input_seq = encoder_input_data[5000 + i : 5000 + i + 1]\n","\n","    # Dự đoán câu trả lời cho câu hỏi đó\n","    predicted_seq = model.predict([input_seq, np.zeros((1, max_decoder_seq_length, num_decoder_tokens))])[0]\n","\n","    # Chuyển đổi predicted_seq và target_seq sang dạng chuỗi ký tự\n","    predicted_seq = [np.argmax(token) for token in predicted_seq]\n","    target_seq = decoder_target_data[5000 + i]\n","    target_seq = [np.argmax(token) for token in target_seq]\n","\n","    predicted_text = ''.join([target_token_index_inv[token] for token in predicted_seq])\n","    target_text = ''.join([target_token_index_inv[token] for token in target_seq])\n","\n","    # Tính BLEU score cho đối chiếu giữa predicted_text và target_text\n","    score = sentence_bleu([target_text], predicted_text)\n","    total_score += score\n","\n","average_score = total_score / test_samples\n","print('Average BLEU Score: {}'.format(average_score))\n","\n","# Phương pháp này được sử dụng để đánh giá mô hình và tính toán các chỉ số như perplexity và BLEU score. \n","# `model.evaluate()` được sử dụng để tính toán hàm mất mát trên tập dữ liệu test, và từ đó tính toán perplexity. \n","# BLEU score được tính toán bằng cách so sánh các câu trả lời được dự đoán với các câu trả lời thực tế trong tập dữ liệu test sử dụng `sentence_bleu()` từ thư viện nltk."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684240060098,"user_tz":-420,"elapsed":2360,"user":{"displayName":"Tengi “10G.SZ” Seizo","userId":"17698370472858551934"}},"outputId":"068082e8-57de-4af4-833a-d8fb2d91cec5","id":"0te_mDQnjFi2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 851ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","Average BLEU Score: 2.2948341863438892e-156\n"]}]},{"cell_type":"markdown","source":["## Seq2Seq With `cornell_movie_dialogs_corpus` data"],"metadata":{"id":"1EEaqTNYCvWS"}},{"cell_type":"code","source":[],"metadata":{"id":"DDapL16qDFWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n","!unzip cornell_movie_dialogs_corpus.zip\n"],"metadata":{"id":"-i4FYIEH5c8b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np\n","import os\n","import re\n","import tensorflow as tf\n","import time"],"metadata":{"id":"iXXpI52f1MUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_conversations():\n","    # Đường dẫn đến file các cuộc đối thoại\n","    filePath=os.path.join(os.getcwd(),'cornell movie-dialogs corpus','movie_lines.txt')\n","    id2line = {}\n","    with open(filePath, errors='ignore') as file:\n","        lines = file.readlines()\n","    for line in lines:\n","        parts = line.replace('\\n', '').split(' +++$+++ ')\n","        id2line[parts[0]] = parts[4]\n","\n","    # Đường dẫn đến file chứa cặp câu hỏi - câu trả lời\n","    filePath=os.path.join(os.getcwd(),'cornell movie-dialogs corpus','movie_conversations.txt')\n","    conversations = []\n","    with open(filePath, 'r') as file:\n","        lines = file.readlines()\n","    for line in lines:\n","        parts = line.replace('\\n', '').split(' +++$+++ ')\n","        convo = []\n","        for part in parts[3][1:-1].split(','):\n","            convo.append(id2line[part])\n","        conversations.append(convo)\n","\n","    return conversations\n"],"metadata":{"id":"7ygf0c6A1Qu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_data():\n","    conversations = load_conversations()\n","\n","    # Chuyển đổi thành các câu hỏi và các câu trả lời\n","    questions = []\n","    answers = []\n","\n","    for conversation in conversations:\n","        for i in range(len(conversation) - 1):\n","            questions.append(conversation[i])\n","            answers.append(conversation[i + 1])\n","\n","    # Chuyển đổi thành các vector đại diện\n","    def clean_text(text):\n","        text = text.lower()\n","        text = re.sub(r\"i'm\", \"i am\", text)\n","        text = re.sub(r\"he's\", \"he is\", text)\n","        text = re.sub(r\"she's\", \"she is\", text)\n","        text = re.sub(r\"that's\", \"that is\", text)\n","        text = re.sub(r\"what's\", \"what is\", text)\n","        text = re.sub(r\"where's\", \"where is\", text)\n","        text = re.sub(r\"\\'ll\", \" will\", text)\n","        text = re.sub(r\"\\'ve\", \" have\", text)\n","        text = re.sub(r\"\\'re\", \" are\", text)\n","        text = re.sub(r\"\\'d\", \" would\", text)\n","        text = re.sub(r\"won't\", \"will not\", text)\n","        text = re.sub(r\"can't\", \"cannot\", text)\n","        text = re.sub(r\"[-()\\\"/@;:<>{}`+=~|.!?,]\", \" \", text)\n","        return text\n","\n","    # Xây dựng bộ từ vựng và các từ token\n","    word2count = {}\n","    for question, answer in zip(questions, answers):\n","        question = clean_text(question)\n","        answer = clean_text(answer)\n","        for word in question.split():\n","            if word not in word2count:\n","                word2count[word] = 1\n","            else:\n","                word2count[word] += 1\n","        for word in answer.split():\n","            if word not in word2count:\n","                word2count[word] = 1\n","            else:\n","                word2count[word] += 1\n","\n","    # Các từ xuất hiện trong ít hơn 5 câu thì sẽ không được sử dụng\n","    threshold = 5\n","    word2index = {}\n","    for word, count in word2count.items():\n","        if count >= threshold:\n","            word2index[word] = len(word2index)\n","\n","    # Thêm các token đặc biệt\n","    tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n","    for token in tokens:\n","        word2index[token] = len(word2index)\n","\n","    index2word = {w_i: w for w, w_i in word2index.items()}\n","\n","    # Thêm token EOS vào câu trả lời\n","    for i in range(len(answers)):\n","        answers[i] += ' <EOS>'\n","\n","    # Chuyển đổi thành các vector đại diện\n","    # Chuyển đổi câu hỏi\n","    questions_to_indices = []\n","    for question in questions:\n","        question = clean_text(question)\n","        words = question.split()\n","        indices = []\n","        for word in words:\n","            if word in word2index:\n","                indices.append(word2index[word])\n","            else:\n","                indices.append(word2index['<OUT>'])\n","        questions_to_indices.append(indices)\n","\n","    # Chuyển đổi câu trả lời    \n","    answers_to_indices = []\n","    for answer in answers:\n","        answer = clean_text(answer)\n","        words = answer.split()\n","        indices = []\n","        for word in words:\n","            if word in word2index:\n","                indices.append(word2index[word])\n","            else:\n","                indices.append(word2index['<OUT>'])\n","        answers_to_indices.append(indices)\n","\n","    # Sắp xếp dữ liệu theo chiều dài của câu hỏi và câu trả lời\n","    sorted_questions = []\n","    sorted_answers = []\n","    for length in range(1, 25 + 1):\n","        for i in enumerate(questions_to_indices):\n","            if len(i[1]) == length:\n","                sorted_questions.append(questions_to_indices[i[0]])\n","                sorted_answers.append(answers_to_indices[i[0]])\n","\n","    return sorted_questions, sorted_answers, word2index, index2word\n"],"metadata":{"id":"JRnUYgQi1Ua3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model():\n","  # Định nghĩa các tham số cho mô hình\n","  encoder_embedding_size = 128\n","  decoder_embedding_size = 128\n","  rnn_size = 128\n","  \n","  # Định nghĩa encoder\n","  encoder_inputs = Input(shape=(None,))\n","  encoder_embeddings = Embedding(len(word2index), encoder_embedding_size)(encoder_inputs)\n","  encoder_rnn = GRU(rnn_size, return_sequences=True, return_state=True)\n","  encoder_outputs, encoder_state = encoder_rnn(encoder_embeddings)\n","  \n","  # Định nghĩa decoder\n","  decoder_inputs = Input(shape=(None,))\n","  decoder_embeddings = Embedding(len(word2index), decoder_embedding_size)(decoder_inputs)\n","  decoder_rnn = GRU(rnn_size, return_sequences=True, return_state=True)\n","  decoder_outputs, _ = decoder_rnn(decoder_embeddings, initial_state=encoder_state)\n","  decoder_dense = Dense(len(word2index), activation='softmax')\n","  decoder_outputs = decoder_dense(decoder_outputs)\n","  \n","  # Xây dựng mô hình toàn cục\n","  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","  \n","  # Compile và trả về mô hình\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","\n","  return model\n"],"metadata":{"id":"Bmpci6ui1XhO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk.translate.bleu_score as bleu\n","def train_model():\n","  # Tải dữ liệu\n","  questions, answers, word2index, index2word = preprocess_data()\n","  \n","  # Phân chia tập huấn luyện và tập kiểm tra\n","  train_X, test_X, train_Y, test_Y = train_test_split(questions, answers, test_size=0.2)\n","  \n","  # Tạo mô hình\n","  model = create_model()\n","\n","  # Tiến hành huấn luyện mô hình\n","  history = model.fit([train_X, train_Y[:,:-1]], train_Y.reshape(train_Y.shape[0], train_Y.shape[1], 1)[:,1:],\n","            epochs=25, batch_size=64, validation_data=([test_X, test_Y[:,:-1]], test_Y.reshape(test_Y.shape[0], test_Y.shape[1], 1)[:,1:]))\n","\n","  print(history.history.keys())\n","  print('Train Loss: ', history.history['loss'])\n","  print('Train Accuracy: ', history.history['acc'])\n","  print('Validation Loss: ', history.history['val_loss'])\n","  print('Validation Accuracy: ', history.history['val_acc'])\n","\n","  #model.fit([train_X, train_Y[:,:-1]], train_Y.reshape(train_Y.shape[0], train_Y.shape[1], 1)[:,1:],\n","   #         epochs=25, batch_size=64, validation_data=([test_X, test_Y[:,:-1]], test_Y.reshape(test_Y.shape[0], test_Y.shape[1], 1)[:,1:]))\n","  \n","  # Lưu trọng số mô hình\n","  model.save_weights(\"model_weights.h5\")\n","  # Load trọng số mô hình đã huấn luyện\n","  model.load_weights(\"model_weights.h5\")\n","\n","  loss, acc = model.evaluate([test_X, test_Y[:,:-1]], test_Y.reshape(test_Y.shape[0], test_Y.shape[1], 1)[:,1:])\n","  print('Test Loss: ', loss)\n","  print('Test Accuracy: ', acc)\n"],"metadata":{"id":"LTjpU_hJ1aiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Xây dựng giao diện dòng lệnh (CLI) cho chatbot\n","while True:\n","    question = input(\"You: \")\n","    answer = predict(question)\n","    print(\"Chatbot: \" + answer)"],"metadata":{"id":"r0Q4Y3TRBkrg"},"execution_count":null,"outputs":[]}]}